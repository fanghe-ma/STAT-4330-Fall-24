\chapter{Class 3}

\today \\

\section{Review of 'no return' problems}

Recall the example from last week. Let $X_1 \hdots X_{2n}$ be iid RVs where $P(X_i = 1) = \frac{1}{2}, P(X_i = -1) = \frac{1}{2}$. \\

Let $S_0 = 0$, $S_j = \sum_{i = 0}^{j}X_i$ for $j = 1, \hdots, 2n$  \\

\textbf{Problem}: Find $P(S_1 > 0, S_2 > 0, \hdots, S_{2n} > 0)$  \\

\textbf{Step 1}: Breaking up the event into a set of disjoint events and summing up their probability \\

The required probability is
\begin{align*}
  &P(S_1 > 0, S_2 > 0, \hdots, S_{2n} > 0) \\
  &=\textcolor{blue}{ \sum_{r = 1}^{\infty} P \left( S_1 > 0, S_2 > 0, \hdots, S_{2n} = 2r \right) }
\end{align*}

\textbf{Step 2}: Count the number of paths from $(0, 0)$ to $(2n, 2r)$ that do not touch the $x$-axis.
\begin{align*}
  &P(S_1 > 0, S_2 > 0, \hdots, S_{2n} > 0) \\
  &= \sum_{r = 1}^{\infty} P \left( S_1 > 0, S_2 > 0, \hdots, S_{2n} = 2r \right) \\
  &= \textcolor{blue}{\sum_{r = 1}^{\infty} \left( \text{Number of paths from origin to $(2n, 2r)$ that do not touch the axis} \right)  \left( \frac{1}{2} \right)^{2n}}
\end{align*}

\textbf{Step 3}: Count the total number of paths from $(0, 0)$ to $(2n, 2r)$, and the number of paths that touch the $x$-axis. 
\begin{align*}
  &P(S_1 > 0, S_2 > 0, \hdots, S_{2n} > 0) \\
  &= \sum_{r = 1}^{\infty} P \left( S_1 > 0, S_2 > 0, \hdots, S_{2n} = 2r \right) \\
  &= \sum_{r = 1}^{\infty} \left( \text{Number of paths from origin to $(2n, 2r)$ that do not touch the axis} \right)  \left( \frac{1}{2} \right)^{2n} \\
  &= \textcolor{blue}{\sum \left( N_{2n-1, 2r-1} - N_{2n -1, 2r + 1} \right)  \left( \frac{1}{2} \right)^{2n}}
\end{align*}

\textbf{Step 4}: Telescopic cancellation.
\begin{align*}
  &P(S_1 > 0, S_2 > 0, \hdots, S_{2n} > 0) \\
  &= \sum_{r = 1}^{\infty} P \left( S_1 > 0, S_2 > 0, \hdots, S_{2n} = 2r \right) \\
  &= \sum_{r = 1}^{\infty} \left( \text{Number of paths from origin to $(2n, 2r)$ that do not touch the axis} \right)  \left( \frac{1}{2} \right)^{2n} \\
  &= \sum \left( N_{2n-1, 2r-1} - N_{2n -1, 2r + 1} \right)  \left( \frac{1}{2} \right)^{2n} \\
  &= \textcolor{blue}{
    \sum_{r =1}^{\infty} \left( N_{2n-1, 2r-1} - N_{2n -1, 2r + 1} \right)  \left( \frac{1}{2} \right)^{2n}
  } \\
  &= \textcolor{blue}{
    N_{2n -1, 1} \left( \frac{1}{2} \right)^{2n}
  }
\end{align*}

\textcolor{red}{Note}: The upper bound for summation, whether $r = n$ or $\infty$, does not matter, because
\begin{itemize}
  \item there are exactly $0$ ways to get to $2n -1$ with $2n+1$ steps 'up'
\end{itemize}

\textbf{Step 5}: Evaluate $N_{2n -1, 1}$ \\

Recall that $N_{2n -1, 1}$ represents $2n - 1$ steps, and ending up at $1$. That means there were $(2n - 1 + 1) \div 2 = n$ steps up, $n - 1$ steps down

\begin{align*}
  N_{2n - 1, 1} &= \begin{pmatrix} 2n -1 \\ n \end{pmatrix}  \\
  &= \frac{(2n-1)!}{n! (n-1)!} \\
  &= \frac{(2n-1)!}{n! (n-1)!} \times \frac{2n}{n} \times \frac{1}{2} \\
  &= \frac{(2n)!}{n! n!} \times \frac{1}{2} \\
  &= \frac{1}{2} \times \begin{pmatrix} 2n \\ n \end{pmatrix} 
\end{align*}

The required probability is

\begin{align*}
  &P(S_1 > 0, S_2 > 0, \hdots, S_{2n} > 0) \\
  &= \sum_{r = 1}^{\infty} P \left( S_1 > 0, S_2 > 0, \hdots, S_{2n} = 2r \right) \\
  &= \sum_{r = 1}^{\infty} \left( \text{Number of paths from origin to $(2n, 2r)$ that do not touch the axis} \right)  \left( \frac{1}{2} \right)^{2n} \\
  &= \sum \left( N_{2n-1, 2r-1} - N_{2n -1, 2r + 1} \right)  \left( \frac{1}{2} \right)^{2n} \\
  &= \sum_{r =1}^{\infty} \left( N_{2n-1, 2r-1} - N_{2n -1, 2r + 1} \right)  \left( \frac{1}{2} \right)^{2n}
   \\
  &= N_{2n -1, 1} \left( \frac{1}{2} \right)^{2n} \\
  &= \textcolor{blue}{ \begin{pmatrix} 2n - 1\\ n \end{pmatrix} \left( \frac{1}{2} \right)^{2n} } \\
  &= \textcolor{blue}{ \frac{1}{2} \times \begin{pmatrix} 2n \\ n \end{pmatrix}  \times  \left( \frac{1}{2} \right)^{2n} }
\end{align*}

\textcolor{red}{\textbf{Step 6}: Recognize that $ \begin{pmatrix} 2n \\ n \end{pmatrix} \left( \frac{1}{2} \right)^{2n} $ is $P(S_{2n} = 0)$}
\begin{align*}
  &P(S_1 > 0, S_2 > 0, \hdots, S_{2n} > 0) \\
  &= \sum_{r = 1}^{\infty} P \left( S_1 > 0, S_2 > 0, \hdots, S_{2n} = 2r \right) \\
  &= \sum_{r = 1}^{\infty} \left( \text{Number of paths from origin to $(2n, 2r)$ that do not touch the axis} \right)  \left( \frac{1}{2} \right)^{2n} \\
  &= \sum \left( N_{2n-1, 2r-1} - N_{2n -1, 2r + 1} \right)  \left( \frac{1}{2} \right)^{2n} \\
  &= \sum_{r =1}^{\infty} \left( N_{2n-1, 2r-1} - N_{2n -1, 2r + 1} \right)  \left( \frac{1}{2} \right)^{2n}
   \\
  &= N_{2n -1, 1} \left( \frac{1}{2} \right)^{2n} \\
  &= \textcolor{blue}{ \begin{pmatrix} 2n - 1\\ n \end{pmatrix} \left( \frac{1}{2} \right)^{2n} } \\
  &= \textcolor{blue}{ \frac{1}{2} \times \begin{pmatrix} 2n \\ n \end{pmatrix}  \times  \left( \frac{1}{2} \right)^{2n} } \\
  &= \frac{1}{2} P \left( S_{2n} = 0 \right) 
\end{align*}

\textbf{Extension idea}: How would we think about 
\[
  P \left( S_1 \neq 0, S_2 \neq 0, \hdots, S_{2n} \neq 0 \right) 
\]

We can break it up into two disjoint pieces
\begin{align*}
  &P \left( S_1 \neq 0, S_2 \neq 0, \hdots, S_{2n} \neq 0 \right)  \\
 =& \left( S_1 > 0, S_2 > 0, \hdots, S_{2n} > 0 \right) + \\
  & \left( S_1 < 0, S_2 < 0, \hdots, S_{2n} < 0 \right) + \\
 =& P \left( S_{2n} = 0 \right) 
\end{align*}

\textcolor{red}{I.E. tossing the coin 100 times, the probability of never having the same number of coins is 
\[
  \begin{pmatrix} 100 \\ 50 \end{pmatrix} \times \left( \frac{1}{2} \right)^{100}
\]}

\section{First return problems}

Problems about the 1st return to $0$. This can only happen on an even toss. \\

Notation:
\[
  f_{2k} = \text{ chance of 1st return to $0$ is at time $2k$}
\]

More concretely
\[
  f_2 = P(\text{H, T}) + P( \text{T, H}) = \frac{1}{4} + \frac{1}{4} = \frac{1}{2}
\]

In general,
\[
  f_{2k} = P \left( S_1 \neq 0, S_2 \neq 0, \hdots, S_{2k - 1} \neq 0, S_{2k} = 0 \right) 
\]

\textbf{Idea 1}: Breaking required event into two pieces \\

Consider the events $(S_1 \neq 0, \hdots S_{2k -1} \neq 0)$ 
\begin{align*}
  A &= (A \cap B) \cup (A \cap B^C) \\
  (S_1 \neq 0, \hdots S_{2k -1} \neq 0) &= \left( S_1 \neq 0, \hdots S_{2k} \neq 0\right) \cup \left( S_1 \neq 0, \hdots, S_{2k} = 0 \right)
\end{align*}

Converting events to probability
\begin{align*}
  P(S_1 \neq 0, \hdots S_{2k -1} \neq 0) &= P\left( S_1 \neq 0, \hdots S_{2k} \neq 0\right) + P\left( S_1 \neq 0, \hdots, S_{2k} = 0 \right)
\end{align*}

\textbf{Idea 2}: Draw connection to 'no return' problems discussed above \\

Note the LHS, since $S_{2k -1}$ cannot be equal to 0, the required probability is 
\[
  P \left( S_1 \neq 0, \hdots S_{2k -1} \neq 0 \right)  = P \left( S_1 \neq 0, \hdots, S_{2k - 2} \neq 0 \right)   = u_{2k - 2}
\]

Note on the RHS, 
\[
  P \left( S_1 \neq 0, \hdots, S_{2k} \neq 0 \right)  = u_{2k}
\]

And the last term 
\[
  P \left( S_1 \neq 0, \hdots, S_{2k -1}  \neq 0, S_{2k} = 0\right) = f_{2k}
\]

Hence
\begin{align*}
  P(S_1 \neq 0, \hdots S_{2k -1} \neq 0) &= P\left( S_1 \neq 0, \hdots S_{2k} \neq 0\right) + P\left( S_1 \neq 0, \hdots, S_{2k} = 0 \right) \\
  u_{2k - 2} &= u_{2k} + f_{2k}
\end{align*}

Hence
\[
  f_{2k} = u_{2k - 2} - u_{2k} \text{ for } k = 1, 2, \hdots 
\]

\textbf{Idea 3}: Taking the infinite union of disjoint events \\

The statement "You eventually return" is the union of "Return for the first time at time 2", "Return for the first time at time 4", $\hdots$ \\

The probability of eventually returning is
\begin{align*}
  &f_2 + f_4 + f_6 + \hdots \\
  =& (u_0 - u_2) + (u_2 - u_4) + \hdots \\
  =& u_0  \\
  =& 1
\end{align*}

\textbf{Note}: $u_0 = P(S_0 = 0) = 1$

\begin{framed}
  Therefore we have used \textbf{elementary, combinatorial} arguments to show that \textbf{we will always return to 0}.
\end{framed}

\section{Expected time to first return}

Note that there is a caveat in calling $T$, the time to first return, a r.v. because r.v.s map from sample space to the real numbers, but the sample space contains a perhaps infinite string of tails (i.e. $T$ will be infinite), which is 'extended real numbers' \\

Let $T$ be the time to first return
\begin{align*}
  E\left[ T\right]  &= \sum_{k = 1}^{\infty} 2k f_{2k}
\end{align*}

where
\begin{align*}
  f_{2k} &= u_{2k - 2} - u_{2k} \\
  &= \begin{pmatrix} 2k - 2 \\ k - 1 \end{pmatrix}  \left( \frac{1}{2} \right)^{2k - 2} - \begin{pmatrix}  2k \\ k \end{pmatrix}  \left( \frac{1}{2} \right)^{2k}
\end{align*}

\textcolor{red}{As with before, we want to express combinatorials in the same 'basis'}. We rewrite
\begin{align*}
  \begin{pmatrix} 2k - 2 \\ k - 1 \end{pmatrix}  &= \frac{(2k - 2)!}{(k-1)! (k-1)!} = \frac{(2k-2)!}{(k-1)! (k-1)!} \times \frac{2k (2k-1)}{k \times k} \times \frac{k^2}{(2k)(2k-1)} \\ 
  &= \frac{(2k)!}{k! k!} \times \frac{k}{4k - 2}
\end{align*}

\textcolor{red}{FILL IN THE BLANKS FOR ALGEBRA LATER}
\begin{align*}
  f_{2k} &= u_{2k - 2} - u_{2k} \\
  &= \begin{pmatrix} 2k - 2 \\ k - 1 \end{pmatrix}  \left( \frac{1}{2} \right)^{2k - 2} - \begin{pmatrix}  2k \\ k \end{pmatrix}  \left( \frac{1}{2} \right)^{2k} \\
  &= \frac{1}{2k - 1} \begin{pmatrix} 2k \\ k \end{pmatrix} \left( \frac{1}{2} \right)^{2k}
\end{align*}

The expected value for $T$ is
\begin{align*}
  E\left[ T\right]  &= \sum 2k f_2k  \\
  &= \sum \frac{2k}{2k - 1} \begin{pmatrix} 2k \\ k \end{pmatrix}  \left( \frac{1}{2}  \right)^{2k}
\end{align*}

To understand the behavior of this, we need to understand $ \begin{pmatrix} 2k \\k \end{pmatrix} $. \\

By \textbf{Stirling's formula}
\[
  n! \sim \sqrt{2 \pi} n^{n + \frac{1}{2}} e^{-n}
\]



















